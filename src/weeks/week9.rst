Week 9  
######

:date: 2018-10-29
:summary: week 9, talking about training data and creativity
:category: weeks
:tags: training, creativity, neural networks



=====
Day 1
=====

A talk on using neural networks "in reverse" to simulate creativity. 
 
.. raw:: html

  <div style="max-width:854px"><div style="position:relative;height:0;padding-bottom:56.25%"><iframe src="https://embed.ted.com/talks/blaise_aguera_y_arcas_how_computers_are_learning_to_be_creative" width="854" height="480" style="position:absolute;left:0;top:0;width:100%;height:100%" frameborder="0" scrolling="no" allowfullscreen></iframe></div></div>


=====
Day 2
=====

 1.  `Download notebook with learning agent here <https://www.dropbox.com/s/wvb8gxyozwt1ln1/Tictac.ipynb?dl=0>`_

 Also download the `helper file here <https://www.dropbox.com/s/5ktb2tim8x3yc20/turtle_board.py?dl=0>`_ to be able to play against the trained agent in experiments 2-4.

 2. Read the code, run the top cell, then run one or more of the experiments.  If you make the parameter **watcher = True** in one of the experiments, you will be able to watch the games as they are played.

 3. You can choose to either: put comments into the function **update_menace()** in the Agent class to explain to yourself what it does, OR, write a new mover function (or copy yours from before) to be able to play your agent against one trained using reinforcement learning.

 4. If you would like to make graphs showing the learning progress like you can see in the Tictac notebook, `download this notebook <https://www.dropbox.com/s/l0ukk1uu7yzie61/make_learning_graph.ipynb?dl=0>`_ and run it in a separate tab in your jupyter lab system.

=====
Day 3
=====

 1. We'll spend the first half of the class continuing to experiment with the tic-tac-toe learning agent -- make sure you have a trained agent, then play against it yourself at least 10 times, noting what kinds of mistakes it makes and what kinds of mistakes it doesn't make.  What do you think are the reasons behind these mistakes?  Do you have any thoughts on what we might do differently in the training to reduce those mistakes?

 2. We're going to watch two videos from Microsoft Research director Eric Horvitz, which address many of the positive aspects of using AI systems and some of the issues, both technical and ethical that one needs to be aware of.  In particular pay attention to the idea of a false positive and a false negative rate -- what does this mean and how does  it relate to the systems we have been working with?

Video 1:

.. raw:: html

   <iframe width="560" height="315" src="https://www.youtube.com/embed/dpoVh9xwdD4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
   

Video 2:

.. raw:: html

  <iframe width="560" height="315" src="https://www.youtube.com/embed/tL7t2O5Iu8E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


Take notes and post questions or thoughts below.


